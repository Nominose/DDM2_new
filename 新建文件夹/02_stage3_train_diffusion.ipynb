{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDM² Stage 3: Diffusion Model Training\n",
    "\n",
    "训练扩散去噪模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# 路径配置 - 换电脑时修改这里\n",
    "#==============================================================================\n",
    "\n",
    "# 项目根目录\n",
    "PROJECT_ROOT = \"/host/d/ddm2\"\n",
    "\n",
    "# 数据路径\n",
    "EXCEL_PATH = \"/host/d/file/fixedCT_static_simulation_train_test_gaussian_local.xlsx\"\n",
    "DATA_ROOT = \"/host/d/file/simulation/\"\n",
    "\n",
    "# Teacher N2N 预测结果\n",
    "TEACHER_N2N_ROOT = \"/host/d/file/pre/noise2noise/pred_images/\"\n",
    "TEACHER_N2N_EPOCH = 78\n",
    "\n",
    "# 直方图均衡化文件\n",
    "BINS_FILE = \"/host/d/file/histogram_equalization/bins.npy\"\n",
    "BINS_MAPPED_FILE = \"/host/d/file/histogram_equalization/bins_mapped.npy\"\n",
    "\n",
    "# 配置文件路径\n",
    "CONFIG_FILE = f\"{PROJECT_ROOT}/config/ct_denoise.json\"\n",
    "\n",
    "# Stage2 文件路径 (由01_stage2生成)\n",
    "STAGE2_FILE = f\"{PROJECT_ROOT}/experiments/ct_denoise_stage2/stage2_matched.txt\"\n",
    "\n",
    "# 实验名称 (输出目录会自动加时间戳)\n",
    "EXPERIMENT_NAME = \"ct_denoise\"\n",
    "\n",
    "#==============================================================================\n",
    "# 训练参数\n",
    "#==============================================================================\n",
    "\n",
    "# 数据集划分\n",
    "TRAIN_BATCHES = [0, 1, 2, 3, 4]  # 训练集\n",
    "VAL_BATCHES = [5]                 # 验证集\n",
    "\n",
    "# 切片范围\n",
    "SLICE_RANGE = [30, 80]\n",
    "\n",
    "# HU值范围\n",
    "HU_MIN = -1000.0\n",
    "HU_MAX = 2000.0\n",
    "\n",
    "# 验证集采样\n",
    "VAL_VOLUME_IDX = 8\n",
    "VAL_SLICE_IDX = [25]\n",
    "\n",
    "# 训练迭代次数\n",
    "N_ITER = 100000\n",
    "PRINT_FREQ = 100\n",
    "VAL_FREQ = 1000\n",
    "SAVE_FREQ = 10000\n",
    "\n",
    "# 恢复训练 (设为checkpoint路径可恢复，如 \"experiments/xxx/checkpoint/latest\")\n",
    "RESUME_STATE = None\n",
    "\n",
    "#==============================================================================\n",
    "# GPU配置\n",
    "#==============================================================================\n",
    "\n",
    "GPU_ID = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "import data as Data\n",
    "import model as Model\n",
    "import core.logger as Logger\n",
    "import core.metrics as Metrics\n",
    "\n",
    "print(f\"工作目录: {os.getcwd()}\")\n",
    "print(f\"GPU: {GPU_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载并更新配置\n",
    "with open(CONFIG_FILE, 'r') as f:\n",
    "    opt = json.load(f)\n",
    "\n",
    "# 更新所有路径\n",
    "for phase in ['train', 'val']:\n",
    "    opt['datasets'][phase]['dataroot'] = EXCEL_PATH\n",
    "    opt['datasets'][phase]['data_root'] = DATA_ROOT\n",
    "    opt['datasets'][phase]['train_batches'] = TRAIN_BATCHES\n",
    "    opt['datasets'][phase]['val_batches'] = VAL_BATCHES\n",
    "    opt['datasets'][phase]['slice_range'] = SLICE_RANGE\n",
    "    opt['datasets'][phase]['HU_MIN'] = HU_MIN\n",
    "    opt['datasets'][phase]['HU_MAX'] = HU_MAX\n",
    "    opt['datasets'][phase]['bins_file'] = BINS_FILE\n",
    "    opt['datasets'][phase]['bins_mapped_file'] = BINS_MAPPED_FILE\n",
    "    opt['datasets'][phase]['teacher_n2n_root'] = TEACHER_N2N_ROOT\n",
    "    opt['datasets'][phase]['teacher_n2n_epoch'] = TEACHER_N2N_EPOCH\n",
    "\n",
    "# 验证集采样设置\n",
    "opt['datasets']['val']['val_volume_idx'] = VAL_VOLUME_IDX\n",
    "opt['datasets']['val']['val_slice_idx'] = VAL_SLICE_IDX\n",
    "\n",
    "# 训练参数\n",
    "opt['train']['n_iter'] = N_ITER\n",
    "opt['train']['print_freq'] = PRINT_FREQ\n",
    "opt['train']['val_freq'] = VAL_FREQ\n",
    "opt['train']['save_checkpoint_freq'] = SAVE_FREQ\n",
    "\n",
    "# Stage2文件\n",
    "opt['stage2_file'] = STAGE2_FILE\n",
    "\n",
    "# 检查stage2文件\n",
    "if not os.path.exists(STAGE2_FILE):\n",
    "    raise FileNotFoundError(f\"Stage2文件不存在: {STAGE2_FILE}\\n请先运行 01_stage2_state_matching.ipynb\")\n",
    "\n",
    "print(f\"Stage2文件: {STAGE2_FILE} (共 {sum(1 for _ in open(STAGE2_FILE))} 行)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置实验目录\n",
    "ts = datetime.now().strftime('%y%m%d_%H%M%S')\n",
    "exp_root = f\"{PROJECT_ROOT}/experiments/{EXPERIMENT_NAME}_{ts}\"\n",
    "\n",
    "opt['name'] = EXPERIMENT_NAME\n",
    "opt['path'] = {\n",
    "    'log': f\"{exp_root}/logs\",\n",
    "    'results': f\"{exp_root}/results\",\n",
    "    'checkpoint': f\"{exp_root}/checkpoint\",\n",
    "    'resume_state': RESUME_STATE,\n",
    "    'experiments_root': exp_root\n",
    "}\n",
    "\n",
    "for p in [opt['path']['log'], opt['path']['results'], opt['path']['checkpoint']]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "opt = Logger.dict_to_nonedict(opt)\n",
    "print(f\"实验目录: {exp_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置日志\n",
    "Logger.setup_logger('base', opt['path']['log'], 'train', level=logging.INFO, screen=True)\n",
    "logger = logging.getLogger('base')\n",
    "\n",
    "# CUDA\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# 数据集\n",
    "train_set = Data.create_dataset(opt['datasets']['train'], 'train', stage2_file=STAGE2_FILE)\n",
    "train_loader = Data.create_dataloader(train_set, opt['datasets']['train'], 'train')\n",
    "val_set = Data.create_dataset(opt['datasets']['val'], 'val', stage2_file=STAGE2_FILE)\n",
    "val_loader = Data.create_dataloader(val_set, opt['datasets']['val'], 'val')\n",
    "\n",
    "logger.info(f'训练集: {len(train_set)}, 验证集: {len(val_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "diffusion = Model.create_model(opt)\n",
    "logger.info('模型初始化完成')\n",
    "\n",
    "# 打印参数量\n",
    "total_params = sum(p.numel() for p in diffusion.netG.parameters())\n",
    "print(f\"模型参数量: {total_params:,}\")\n",
    "\n",
    "current_step = diffusion.begin_step\n",
    "current_epoch = diffusion.begin_epoch\n",
    "n_iter = opt['train']['n_iter']\n",
    "\n",
    "diffusion.set_new_noise_schedule(opt['model']['beta_schedule']['train'], schedule_phase='train')\n",
    "print(f\"训练目标: {n_iter} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练循环\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "pbar = tqdm(total=n_iter - current_step, desc=\"Training\")\n",
    "\n",
    "try:\n",
    "    while current_step < n_iter:\n",
    "        current_epoch += 1\n",
    "        for _, train_data in enumerate(train_loader):\n",
    "            current_step += 1\n",
    "            if current_step > n_iter:\n",
    "                break\n",
    "            \n",
    "            diffusion.feed_data(train_data)\n",
    "            diffusion.optimize_parameters()\n",
    "            pbar.update(1)\n",
    "            \n",
    "            if current_step % opt['train']['print_freq'] == 0:\n",
    "                logs = diffusion.get_current_log()\n",
    "                logger.info(f'<epoch:{current_epoch}, iter:{current_step}> l_pix: {logs[\"l_pix\"]:.4e}')\n",
    "                pbar.set_postfix({'loss': f\"{logs['l_pix']:.4e}\"})\n",
    "            \n",
    "            if current_step % opt['train']['val_freq'] == 0:\n",
    "                result_path = f\"{opt['path']['results']}/{current_epoch}\"\n",
    "                os.makedirs(result_path, exist_ok=True)\n",
    "                diffusion.set_new_noise_schedule(opt['model']['beta_schedule']['val'], schedule_phase='val')\n",
    "                for idx, val_data in enumerate(val_loader):\n",
    "                    diffusion.feed_data(val_data)\n",
    "                    diffusion.test(continous=True)\n",
    "                    visuals = diffusion.get_current_visuals()\n",
    "                    Metrics.save_img(Metrics.tensor2img(visuals['denoised']), f'{result_path}/{current_step}_{idx}_denoised.png')\n",
    "                    Metrics.save_img(Metrics.tensor2img(visuals['X']), f'{result_path}/{current_step}_{idx}_input.png')\n",
    "                diffusion.set_new_noise_schedule(opt['model']['beta_schedule']['train'], schedule_phase='train')\n",
    "                logger.info(f'验证完成，结果保存在: {result_path}')\n",
    "            \n",
    "            if current_step % opt['train']['save_checkpoint_freq'] == 0:\n",
    "                logger.info('保存checkpoint...')\n",
    "                diffusion.save_network(current_epoch, current_step, save_last_only=True)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    logger.info('训练中断，保存模型...')\n",
    "    diffusion.save_network(current_epoch, current_step, save_last_only=True)\n",
    "finally:\n",
    "    pbar.close()\n",
    "\n",
    "# 保存最终模型\n",
    "diffusion.save_network(current_epoch, current_step, save_last_only=True)\n",
    "logger.info(f'训练完成! 模型保存在: {opt[\"path\"][\"checkpoint\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
