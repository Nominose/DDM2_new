{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDM² Stage 2: State Matching\n",
    "\n",
    "对训练集所有数据进行状态匹配，完成后自动更新config文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# 路径配置 - 换电脑时修改这里\n",
    "#==============================================================================\n",
    "\n",
    "# 项目根目录\n",
    "PROJECT_ROOT = \"/host/d/ddm2\"\n",
    "\n",
    "# 数据路径\n",
    "EXCEL_PATH = \"/host/d/file/fixedCT_static_simulation_train_test_gaussian_local.xlsx\"\n",
    "DATA_ROOT = \"/host/d/file/simulation/\"\n",
    "\n",
    "# Teacher N2N 预测结果\n",
    "TEACHER_N2N_ROOT = \"/host/d/file/pre/noise2noise/pred_images/\"\n",
    "TEACHER_N2N_EPOCH = 78\n",
    "\n",
    "# 直方图均衡化文件\n",
    "BINS_FILE = \"/host/d/file/histogram_equalization/bins.npy\"\n",
    "BINS_MAPPED_FILE = \"/host/d/file/histogram_equalization/bins_mapped.npy\"\n",
    "\n",
    "# 配置文件路径\n",
    "CONFIG_FILE = f\"{PROJECT_ROOT}/config/ct_denoise.json\"\n",
    "\n",
    "# Stage2 输出目录\n",
    "STAGE2_OUTPUT_DIR = f\"{PROJECT_ROOT}/experiments/ct_denoise_stage2\"\n",
    "STAGE2_OUTPUT_FILE = \"stage2_matched.txt\"\n",
    "\n",
    "#==============================================================================\n",
    "# 训练参数\n",
    "#==============================================================================\n",
    "\n",
    "# 数据集划分\n",
    "TRAIN_BATCHES = [0, 1, 2, 3, 4]  # 训练集\n",
    "VAL_BATCHES = [5]                 # 验证集\n",
    "\n",
    "# 切片范围\n",
    "SLICE_RANGE = [30, 80]\n",
    "\n",
    "# HU值范围\n",
    "HU_MIN = -1000.0\n",
    "HU_MAX = 2000.0\n",
    "\n",
    "#==============================================================================\n",
    "# GPU配置\n",
    "#==============================================================================\n",
    "\n",
    "GPU_ID = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU_ID\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from functools import partial\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import data as Data\n",
    "import core.logger as Logger\n",
    "\n",
    "print(f\"工作目录: {os.getcwd()}\")\n",
    "print(f\"GPU: {GPU_ID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载并更新配置\n",
    "with open(CONFIG_FILE, 'r') as f:\n",
    "    opt = json.load(f)\n",
    "\n",
    "# 更新所有路径\n",
    "for phase in ['train', 'val']:\n",
    "    opt['datasets'][phase]['dataroot'] = EXCEL_PATH\n",
    "    opt['datasets'][phase]['data_root'] = DATA_ROOT\n",
    "    opt['datasets'][phase]['train_batches'] = TRAIN_BATCHES\n",
    "    opt['datasets'][phase]['val_batches'] = VAL_BATCHES\n",
    "    opt['datasets'][phase]['slice_range'] = SLICE_RANGE\n",
    "    opt['datasets'][phase]['HU_MIN'] = HU_MIN\n",
    "    opt['datasets'][phase]['HU_MAX'] = HU_MAX\n",
    "    opt['datasets'][phase]['bins_file'] = BINS_FILE\n",
    "    opt['datasets'][phase]['bins_mapped_file'] = BINS_MAPPED_FILE\n",
    "    opt['datasets'][phase]['teacher_n2n_root'] = TEACHER_N2N_ROOT\n",
    "    opt['datasets'][phase]['teacher_n2n_epoch'] = TEACHER_N2N_EPOCH\n",
    "\n",
    "# 设置stage2输出路径\n",
    "stage2_file = os.path.join(STAGE2_OUTPUT_DIR, STAGE2_OUTPUT_FILE)\n",
    "opt['stage2_file'] = stage2_file\n",
    "\n",
    "opt = Logger.dict_to_nonedict(opt)\n",
    "print(f\"配置加载完成\")\n",
    "print(f\"Stage2输出: {stage2_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "dataset_opt = dict(opt['datasets']['train'])\n",
    "dataset_opt['use_shuffle'] = False\n",
    "dataset_opt['batch_size'] = 1\n",
    "dataset_opt['num_workers'] = 0\n",
    "dataset_opt['lr_flip'] = 0.0\n",
    "\n",
    "train_set = Data.create_dataset(dataset_opt, 'train')\n",
    "train_loader = Data.create_dataloader(train_set, dataset_opt, 'val')\n",
    "print(f'训练集大小: {len(train_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beta schedule\n",
    "def _rev_warmup_beta(linear_start, linear_end, n_timestep, warmup_frac):\n",
    "    betas = linear_start * np.ones(n_timestep, dtype=np.float64)\n",
    "    warmup_time = int(n_timestep * warmup_frac)\n",
    "    betas[n_timestep - warmup_time:] = np.linspace(\n",
    "        linear_start, linear_end, warmup_time, dtype=np.float64)\n",
    "    return betas\n",
    "\n",
    "to_torch = partial(torch.tensor, dtype=torch.float32, device='cuda:0')\n",
    "betas = _rev_warmup_beta(\n",
    "    opt['noise_model']['beta_schedule']['linear_start'],\n",
    "    opt['noise_model']['beta_schedule']['linear_end'],\n",
    "    1000, 0.7)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = np.cumprod(alphas, axis=0)\n",
    "sqrt_alphas_cumprod_prev = to_torch(np.sqrt(np.append(1., alphas_cumprod)))\n",
    "print(\"Beta schedule 计算完成\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 状态匹配\n",
    "os.makedirs(STAGE2_OUTPUT_DIR, exist_ok=True)\n",
    "stage_file = open(stage2_file, 'w+')\n",
    "idx = 0\n",
    "\n",
    "for _, data in tqdm(enumerate(train_loader), total=len(train_loader), desc=\"State Matching\"):\n",
    "    idx += 1\n",
    "    volume_idx, slice_idx = train_set.samples[idx - 1]\n",
    "    \n",
    "    if 'denoised' not in data:\n",
    "        stage_file.write('%d_%d_%d\\n' % (volume_idx, slice_idx, 500))\n",
    "        continue\n",
    "    \n",
    "    denoised = data['denoised'].cuda()\n",
    "    X = data['X'].cuda()\n",
    "    \n",
    "    min_lh, min_t, prev_diff = 999, -1, 999.\n",
    "    for t in range(sqrt_alphas_cumprod_prev.shape[0]):\n",
    "        noise = X - sqrt_alphas_cumprod_prev[t] * denoised\n",
    "        noise = noise - torch.mean(noise)\n",
    "        mu, std = norm.fit(noise.cpu().numpy())\n",
    "        diff = np.abs((1 - sqrt_alphas_cumprod_prev[t]**2).sqrt().cpu().numpy() - std)\n",
    "        if diff < min_lh:\n",
    "            min_lh, min_t = diff, t\n",
    "        if diff > prev_diff:\n",
    "            break\n",
    "        prev_diff = diff\n",
    "    \n",
    "    stage_file.write('%d_%d_%d\\n' % (volume_idx, slice_idx, min_t))\n",
    "\n",
    "stage_file.close()\n",
    "print(f'\\n状态匹配完成! 输出: {stage2_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更新config文件中的stage2_file路径\n",
    "with open(CONFIG_FILE, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "config['stage2_file'] = stage2_file\n",
    "\n",
    "with open(CONFIG_FILE, 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(f\"已更新 {CONFIG_FILE}\")\n",
    "print(f\"stage2_file = {stage2_file}\")\n",
    "print(\"\\n可以运行 Stage 3 了!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
