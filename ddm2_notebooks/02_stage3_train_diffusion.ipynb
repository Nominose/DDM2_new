{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDM² Stage 3: Train Diffusion Model\n",
    "\n",
    "使用Stage 2的匹配结果训练扩散模型。\n",
    "\n",
    "训练目标: 给定噪声图像和时间步t，预测去噪后的图像。\n",
    "\n",
    "确保Stage 2已完成，修改配置后运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==============================================================================\n",
    "# 基础路径配置\n",
    "#==============================================================================\n",
    "\n",
    "PROJECT_ROOT = \"/host/c/Users/ROG/Documents/Github/DDM2_new\"         # 项目根目录\n",
    "CONFIG_FILE = \"config/ct_denoise.json\" # 配置文件路径 (相对于PROJECT_ROOT)\n",
    "GPU_ID = \"0\"                           # 使用的GPU编号\n",
    "\n",
    "#==============================================================================\n",
    "# 数据路径\n",
    "#==============================================================================\n",
    "\n",
    "EXCEL_PATH = \"/host/d/file/fixedCT_static_simulation_train_test_gaussian_local.xlsx\"  # 数据索引Excel文件\n",
    "DATA_ROOT = \"/host/d/file/simulation/\"                    # CT数据根目录\n",
    "TEACHER_N2N_ROOT = \"/host/d/file/pre/noise2noise/pred_images/\"  # Teacher N2N预测结果目录\n",
    "TEACHER_N2N_EPOCH = 78                                    # 使用Teacher N2N的哪个epoch\n",
    "BINS_FILE = \"/host/d/file/histogram_equalization/bins.npy\"        # 直方图均衡化bins文件\n",
    "BINS_MAPPED_FILE = \"/host/d/file/histogram_equalization/bins_mapped.npy\"  # 直方图均衡化映射文件\n",
    "\n",
    "# Stage2 匹配文件 (由Stage2生成)\n",
    "# 文件格式: 每行 volume_idx_slice_idx_t，例如 \"3_45_156\" 表示第3个case的第45层切片对应t=156\n",
    "STAGE2_FILE = \"experiments/ct_denoise_teacher/stage2_matched.txt\"\n",
    "\n",
    "#==============================================================================\n",
    "# 数据集划分\n",
    "#\n",
    "# 数据组织结构:\n",
    "#   - batch: 一组病例 (例如batch 0-4为训练集，batch 5为验证集)\n",
    "#   - volume: 一个病例/case，即一个完整的3D CT扫描\n",
    "#   - slice: volume中的一个2D切片\n",
    "#\n",
    "# 例如: volume_idx=3, slice_idx=45 表示第3个病例的第45层切片\n",
    "#==============================================================================\n",
    "\n",
    "TRAIN_BATCHES = [0, 1, 2, 3, 4]  # 训练集使用的batch编号\n",
    "VAL_BATCHES = [5]                # 验证集使用的batch编号\n",
    "\n",
    "SLICE_RANGE = [30, 80]  # 每个volume使用的切片范围 [start, end)\n",
    "                        # 例如[30, 80]表示使用第30-79层，共50层\n",
    "\n",
    "# 验证时的采样 (训练过程中验证用少量样本即可，节省时间)\n",
    "VAL_VOLUME_IDX = \"all\"      # 验证用哪个volume(case): 数字表示具体case编号\n",
    "VAL_SLICE_IDX = 25    # 验证用哪些slice: 列表如 [25] 表示只用第25层\n",
    "                         # 训练时只需少量样本看趋势，完整评估在test阶段做\n",
    "\n",
    "#==============================================================================\n",
    "# 预处理参数\n",
    "#==============================================================================\n",
    "\n",
    "HU_MIN = -1000.0  # CT值(HU)下限，低于此值会被clip\n",
    "HU_MAX = 2000.0   # CT值(HU)上限，高于此值会被clip\n",
    "                  # 典型值: 空气=-1000, 水=0, 骨骼=1000+\n",
    "\n",
    "HISTOGRAM_EQUALIZATION = True  # 是否启用直方图均衡化 (需与Stage2一致)\n",
    "\n",
    "#==============================================================================\n",
    "# 训练参数\n",
    "#==============================================================================\n",
    "\n",
    "N_ITER = 400000     # 总训练迭代次数 (iteration)\n",
    "                    # 一个iteration = 处理一个batch\n",
    "                    \n",
    "\n",
    "VAL_FREQ = 1000      # 每多少iter验证一次\n",
    "                    # 验证时会保存去噪结果图片到 results/ 目录\n",
    "\n",
    "SAVE_FREQ = 10000   # 每多少iter保存一次checkpoint\n",
    "                    # checkpoint保存在 experiments/{name}/checkpoint/\n",
    "\n",
    "PRINT_FREQ = 100    # 每多少iter打印一次loss\n",
    "\n",
    "LEARNING_RATE = 1e-4  # 学习率\n",
    "                      \n",
    "\n",
    "BATCH_SIZE = 1      # 每次训练的样本数\n",
    "                    # 512x512图像较大，通常用1-4\n",
    "                    # 增大batch需要更多显存\n",
    "\n",
    "#==============================================================================\n",
    "# 断点续训 (可选)\n",
    "#==============================================================================\n",
    "\n",
    "RESUME_STATE = None  # 断点续训: 设为checkpoint路径\n",
    "                     # 例如: \"experiments/ct_denoise/checkpoint/I100000_E29\"\n",
    "                     # None表示从头训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config已更新: config/ct_denoise.json\n",
      "Stage2文件: experiments/ct_denoise_teacher/stage2_matched.txt\n",
      "\n",
      "训练参数:\n",
      "  总迭代次数: 200,000\n",
      "  验证频率: 每1000iter\n",
      "  保存频率: 每10,000iter\n",
      "  学习率: 0.0001\n",
      "  Batch size: 1\n",
      "\n",
      "断点续训: 从头训练\n"
     ]
    }
   ],
   "source": [
    "# 更新config文件\n",
    "import os, json\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "with open(CONFIG_FILE, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# 更新 datasets.train\n",
    "config['datasets']['train']['dataroot'] = EXCEL_PATH\n",
    "config['datasets']['train']['data_root'] = DATA_ROOT\n",
    "config['datasets']['train']['teacher_n2n_root'] = TEACHER_N2N_ROOT\n",
    "config['datasets']['train']['teacher_n2n_epoch'] = TEACHER_N2N_EPOCH\n",
    "config['datasets']['train']['bins_file'] = BINS_FILE\n",
    "config['datasets']['train']['bins_mapped_file'] = BINS_MAPPED_FILE\n",
    "config['datasets']['train']['train_batches'] = TRAIN_BATCHES\n",
    "config['datasets']['train']['val_batches'] = VAL_BATCHES\n",
    "config['datasets']['train']['slice_range'] = SLICE_RANGE\n",
    "config['datasets']['train']['HU_MIN'] = HU_MIN\n",
    "config['datasets']['train']['HU_MAX'] = HU_MAX\n",
    "config['datasets']['train']['histogram_equalization'] = HISTOGRAM_EQUALIZATION\n",
    "config['datasets']['train']['batch_size'] = BATCH_SIZE\n",
    "\n",
    "# 更新 datasets.val\n",
    "config['datasets']['val']['dataroot'] = EXCEL_PATH\n",
    "config['datasets']['val']['data_root'] = DATA_ROOT\n",
    "config['datasets']['val']['teacher_n2n_root'] = TEACHER_N2N_ROOT\n",
    "config['datasets']['val']['teacher_n2n_epoch'] = TEACHER_N2N_EPOCH\n",
    "config['datasets']['val']['bins_file'] = BINS_FILE\n",
    "config['datasets']['val']['bins_mapped_file'] = BINS_MAPPED_FILE\n",
    "config['datasets']['val']['train_batches'] = VAL_BATCHES\n",
    "config['datasets']['val']['val_batches'] = VAL_BATCHES\n",
    "config['datasets']['val']['slice_range'] = SLICE_RANGE\n",
    "config['datasets']['val']['val_volume_idx'] = VAL_VOLUME_IDX\n",
    "config['datasets']['val']['val_slice_idx'] = VAL_SLICE_IDX\n",
    "config['datasets']['val']['HU_MIN'] = HU_MIN\n",
    "config['datasets']['val']['HU_MAX'] = HU_MAX\n",
    "config['datasets']['val']['histogram_equalization'] = HISTOGRAM_EQUALIZATION\n",
    "\n",
    "# 更新训练参数\n",
    "config['train']['n_iter'] = N_ITER\n",
    "config['train']['val_freq'] = VAL_FREQ\n",
    "config['train']['save_checkpoint_freq'] = SAVE_FREQ\n",
    "config['train']['print_freq'] = PRINT_FREQ\n",
    "config['train']['optimizer']['lr'] = LEARNING_RATE\n",
    "\n",
    "# 更新路径\n",
    "config['stage2_file'] = STAGE2_FILE\n",
    "config['path']['resume_state'] = RESUME_STATE\n",
    "\n",
    "with open(CONFIG_FILE, 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "\n",
    "print(f\"Config已更新: {CONFIG_FILE}\")\n",
    "print(f\"Stage2文件: {STAGE2_FILE}\")\n",
    "print(f\"\\n训练参数:\")\n",
    "print(f\"  总迭代次数: {N_ITER:,}\")\n",
    "print(f\"  验证频率: 每{VAL_FREQ}iter\")\n",
    "print(f\"  保存频率: 每{SAVE_FREQ:,}iter\")\n",
    "print(f\"  学习率: {LEARNING_RATE}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"\\n断点续训: {RESUME_STATE if RESUME_STATE else '从头训练'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stage2文件存在: 3500 个样本\n",
      "  预计训练 57.1 个epoch\n"
     ]
    }
   ],
   "source": [
    "# 检查stage2文件是否存在\n",
    "if os.path.exists(STAGE2_FILE):\n",
    "    with open(STAGE2_FILE, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    print(f\"✓ Stage2文件存在: {len(lines)} 个样本\")\n",
    "    \n",
    "    # 预估训练epoch数\n",
    "    samples_per_epoch = len(lines)\n",
    "    total_epochs = N_ITER * BATCH_SIZE / samples_per_epoch\n",
    "    print(f\"  预计训练 {total_epochs:.1f} 个epoch\")\n",
    "else:\n",
    "    print(f\"⚠ Stage2文件不存在: {STAGE2_FILE}\")\n",
    "    print(\"请先运行 01_stage2_state_matching.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.7\n",
      "export CUDA_VISIBLE_DEVICES=0\n",
      "26-01-03 15:15:40.221 - INFO:   name: ct_denoise\n",
      "  phase: train\n",
      "  gpu_ids: [0]\n",
      "  path:[\n",
      "    log: experiments/ct_denoise_260103_151540/logs\n",
      "    tb_logger: experiments/ct_denoise_260103_151540/tb_logger\n",
      "    results: experiments/ct_denoise_260103_151540/results\n",
      "    checkpoint: experiments/ct_denoise_260103_151540/checkpoint\n",
      "    resume_state: None\n",
      "    experiments: experiments\n",
      "    experiments_root: experiments/ct_denoise_260103_151540\n",
      "  ]\n",
      "  datasets:[\n",
      "    train:[\n",
      "      name: ct\n",
      "      dataroot: /host/d/file/fixedCT_static_simulation_train_test_gaussian_local.xlsx\n",
      "      data_root: /host/d/file/simulation/\n",
      "      train_batches: [0, 1, 2, 3, 4]\n",
      "      val_batches: [5]\n",
      "      valid_mask: [0, 1000]\n",
      "      slice_range: [30, 80]\n",
      "      phase: train\n",
      "      padding: 3\n",
      "      val_volume_idx: all\n",
      "      val_slice_idx: all\n",
      "      batch_size: 1\n",
      "      in_channel: 1\n",
      "      num_workers: 4\n",
      "      use_shuffle: True\n",
      "      image_size: 512\n",
      "      lr_flip: 0.5\n",
      "      HU_MIN: -1000.0\n",
      "      HU_MAX: 2000.0\n",
      "      histogram_equalization: True\n",
      "      bins_file: /host/d/file/histogram_equalization/bins.npy\n",
      "      bins_mapped_file: /host/d/file/histogram_equalization/bins_mapped.npy\n",
      "      teacher_n2n_root: /host/d/file/pre/noise2noise/pred_images/\n",
      "      teacher_n2n_epoch: 78\n",
      "    ]\n",
      "    val:[\n",
      "      name: ct\n",
      "      dataroot: /host/d/file/fixedCT_static_simulation_train_test_gaussian_local.xlsx\n",
      "      data_root: /host/d/file/simulation/\n",
      "      train_batches: [5]\n",
      "      val_batches: [5]\n",
      "      valid_mask: [0, 1000]\n",
      "      slice_range: [30, 80]\n",
      "      phase: val\n",
      "      padding: 3\n",
      "      val_volume_idx: all\n",
      "      val_slice_idx: 25\n",
      "      batch_size: 1\n",
      "      in_channel: 1\n",
      "      num_workers: 0\n",
      "      image_size: 512\n",
      "      lr_flip: 0.0\n",
      "      HU_MIN: -1000.0\n",
      "      HU_MAX: 2000.0\n",
      "      histogram_equalization: True\n",
      "      bins_file: /host/d/file/histogram_equalization/bins.npy\n",
      "      bins_mapped_file: /host/d/file/histogram_equalization/bins_mapped.npy\n",
      "      teacher_n2n_root: /host/d/file/pre/noise2noise/pred_images/\n",
      "      teacher_n2n_epoch: 78\n",
      "      data_len: 3\n",
      "    ]\n",
      "  ]\n",
      "  model:[\n",
      "    which_model_G: mri\n",
      "    finetune_norm: False\n",
      "    drop_rate: 0.0\n",
      "    unet:[\n",
      "      in_channel: 1\n",
      "      out_channel: 1\n",
      "      inner_channel: 32\n",
      "      norm_groups: 32\n",
      "      channel_multiplier: [1, 2, 4, 8, 8]\n",
      "      attn_res: [16]\n",
      "      res_blocks: 2\n",
      "      dropout: 0.0\n",
      "      version: v1\n",
      "    ]\n",
      "    beta_schedule:[\n",
      "      train:[\n",
      "        schedule: rev_warmup70\n",
      "        n_timestep: 1000\n",
      "        linear_start: 5e-05\n",
      "        linear_end: 0.01\n",
      "      ]\n",
      "      val:[\n",
      "        schedule: rev_warmup70\n",
      "        n_timestep: 1000\n",
      "        linear_start: 5e-05\n",
      "        linear_end: 0.01\n",
      "      ]\n",
      "    ]\n",
      "    diffusion:[\n",
      "      image_size: 512\n",
      "      channels: 1\n",
      "      conditional: True\n",
      "    ]\n",
      "  ]\n",
      "  train:[\n",
      "    n_iter: 200000\n",
      "    val_freq: 1000\n",
      "    save_checkpoint_freq: 10000\n",
      "    print_freq: 100\n",
      "    optimizer:[\n",
      "      type: adam\n",
      "      lr: 0.0001\n",
      "    ]\n",
      "    ema_scheduler:[\n",
      "      step_start_ema: 5000\n",
      "      update_ema_every: 1\n",
      "      ema_decay: 0.9999\n",
      "    ]\n",
      "  ]\n",
      "  noise_model:[\n",
      "    resume_state: None\n",
      "    initial_stage_file: None\n",
      "    drop_rate: 0.0\n",
      "    unet:[\n",
      "      in_channel: 2\n",
      "      out_channel: 1\n",
      "      inner_channel: 32\n",
      "      norm_groups: 32\n",
      "      channel_multiplier: [1, 2, 4, 8, 8]\n",
      "      attn_res: [16]\n",
      "      res_blocks: 2\n",
      "      dropout: 0.0\n",
      "      version: v1\n",
      "    ]\n",
      "    beta_schedule:[\n",
      "      linear_start: 5e-05\n",
      "      linear_end: 0.01\n",
      "    ]\n",
      "    n_iter: 50000\n",
      "    val_freq: 200\n",
      "    save_checkpoint_freq: 10000\n",
      "    print_freq: 100\n",
      "    optimizer:[\n",
      "      type: adam\n",
      "      lr: 0.0001\n",
      "    ]\n",
      "  ]\n",
      "  stage2_file: experiments/ct_denoise_teacher/stage2_matched.txt\n",
      "  data:[\n",
      "    excel_path: /host/d/file/fixedCT_static_simulation_train_test_gaussian_local.xlsx\n",
      "    data_root: /host/d/file/simulation/\n",
      "    teacher_n2n_root: /host/d/file/pre/noise2noise/pred_images/\n",
      "    teacher_n2n_epoch: 78\n",
      "    bins_path: /host/d/file/histogram_equalization/bins.npy\n",
      "    bins_mapped_path: /host/d/file/histogram_equalization/bins_mapped.npy\n",
      "    stage2_file: experiments/ct_denoise_teacher/stage2_matched.txt\n",
      "  ]\n",
      "  distributed: False\n",
      "\n",
      "[train] Histogram equalization enabled:\n",
      "    bins: /host/d/file/histogram_equalization/bins.npy (shape: (2301,))\n",
      "    bins_mapped: /host/d/file/histogram_equalization/bins_mapped.npy (shape: (2301,))\n",
      "Found 69 N2N pairs\n",
      "[Slice Detection] Noise: 100 slices, Teacher: 50 slices\n",
      "[Slice Detection] Best offset: 30, correlation: 0.9998\n",
      "[OK] Slice offset verified: 30\n",
      "[train] CTDataset: pairs=69, slices=50, samples=3450\n",
      "[train] Noise slice_range: [30, 80)\n",
      "[train] HU range: [-1000.0, 2000.0]\n",
      "[train] Histogram equalization: True\n",
      "[train] Using teacher N2N from: /host/d/file/pre/noise2noise/pred_images/\n",
      "26-01-03 15:15:43.448 - INFO: CT dataset [ct] is created. Size: 3450\n",
      "[val] Histogram equalization enabled:\n",
      "    bins: /host/d/file/histogram_equalization/bins.npy (shape: (2301,))\n",
      "    bins_mapped: /host/d/file/histogram_equalization/bins_mapped.npy (shape: (2301,))\n",
      "Found 14 N2N pairs\n",
      "[Slice Detection] Noise: 100 slices, Teacher: 50 slices\n",
      "[Slice Detection] Best offset: 30, correlation: 0.9998\n",
      "[OK] Slice offset verified: 30\n",
      "[val] CTDataset: pairs=14, slices=50, samples=1\n",
      "[val] Noise slice_range: [30, 80)\n",
      "[val] HU range: [-1000.0, 2000.0]\n",
      "[val] Histogram equalization: True\n",
      "[val] Using teacher N2N from: /host/d/file/pre/noise2noise/pred_images/\n",
      "26-01-03 15:15:46.140 - INFO: CT dataset [ct] is created. Size: 1\n",
      "26-01-03 15:15:46.140 - INFO: Initial Dataset Finished\n",
      "dropout 0.0 encoder dropout 0.0\n",
      "dropout 0.0 encoder dropout 0.0\n",
      "New beta scheduler set! rev_warmup70\n",
      "26-01-03 15:15:47.491 - INFO: Initialization method [orthogonal]\n",
      "s2s noise activated!\n",
      "New beta scheduler set! rev_warmup70\n",
      "Optimizing: 337 params\n",
      "26-01-03 15:15:48.194 - INFO: [DDM2] is created.\n",
      "26-01-03 15:15:48.194 - INFO: Initial Model Finished\n",
      "26-01-03 15:16:24.878 - INFO: <epoch:  1, iter:     100> l_pix: 4.3570e-02 \n",
      "26-01-03 15:16:44.380 - INFO: <epoch:  1, iter:     200> l_pix: 1.6363e-02 \n",
      "26-01-03 15:17:12.810 - INFO: <epoch:  1, iter:     300> l_pix: 1.4144e-02 \n",
      "26-01-03 15:17:41.037 - INFO: <epoch:  1, iter:     400> l_pix: 2.4741e-02 \n",
      "26-01-03 15:18:07.213 - INFO: <epoch:  1, iter:     500> l_pix: 3.9685e-02 \n",
      "26-01-03 15:18:35.028 - INFO: <epoch:  1, iter:     600> l_pix: 1.1955e-02 \n",
      "26-01-03 15:18:57.740 - INFO: <epoch:  1, iter:     700> l_pix: 1.4055e-02 \n",
      "26-01-03 15:19:17.724 - INFO: <epoch:  1, iter:     800> l_pix: 1.7705e-02 \n",
      "26-01-03 15:19:36.183 - INFO: <epoch:  1, iter:     900> l_pix: 6.7869e-03 \n",
      "26-01-03 15:19:56.081 - INFO: <epoch:  1, iter:   1,000> l_pix: 1.2327e-02 \n",
      "New beta scheduler set! rev_warmup70\n",
      "sampling loop time step: 100%|██████████████████| 34/34 [00:13<00:00,  2.54it/s]\n",
      "New beta scheduler set! rev_warmup70\n",
      "26-01-03 15:20:29.846 - INFO: <epoch:  1, iter:   1,100> l_pix: 9.8961e-03 \n",
      "26-01-03 15:20:48.813 - INFO: <epoch:  1, iter:   1,200> l_pix: 1.2497e-02 \n",
      "26-01-03 15:21:09.909 - INFO: <epoch:  1, iter:   1,300> l_pix: 1.5517e-02 \n",
      "26-01-03 15:21:30.919 - INFO: <epoch:  1, iter:   1,400> l_pix: 1.4385e-02 \n",
      "26-01-03 15:21:50.359 - INFO: <epoch:  1, iter:   1,500> l_pix: 4.3645e-03 \n",
      "26-01-03 15:22:11.289 - INFO: <epoch:  1, iter:   1,600> l_pix: 3.8523e-03 \n",
      "26-01-03 15:22:32.868 - INFO: <epoch:  1, iter:   1,700> l_pix: 3.5180e-03 \n",
      "26-01-03 15:22:52.934 - INFO: <epoch:  1, iter:   1,800> l_pix: 7.5798e-03 \n",
      "26-01-03 15:23:14.482 - INFO: <epoch:  1, iter:   1,900> l_pix: 4.0655e-03 \n",
      "26-01-03 15:23:36.136 - INFO: <epoch:  1, iter:   2,000> l_pix: 4.1050e-03 \n",
      "New beta scheduler set! rev_warmup70\n",
      "sampling loop time step: 100%|██████████████████| 34/34 [00:08<00:00,  3.92it/s]\n",
      "New beta scheduler set! rev_warmup70\n",
      "26-01-03 15:24:06.664 - INFO: <epoch:  1, iter:   2,100> l_pix: 3.1360e-03 \n",
      "26-01-03 15:24:26.671 - INFO: <epoch:  1, iter:   2,200> l_pix: 7.4455e-03 \n",
      "26-01-03 15:24:48.078 - INFO: <epoch:  1, iter:   2,300> l_pix: 5.8666e-03 \n",
      "26-01-03 15:25:09.647 - INFO: <epoch:  1, iter:   2,400> l_pix: 2.5602e-03 \n",
      "26-01-03 15:25:30.149 - INFO: <epoch:  1, iter:   2,500> l_pix: 1.2085e-02 \n",
      "26-01-03 15:25:57.585 - INFO: <epoch:  1, iter:   2,600> l_pix: 2.1439e-03 \n",
      "26-01-03 15:26:25.060 - INFO: <epoch:  1, iter:   2,700> l_pix: 7.2352e-03 \n",
      "26-01-03 15:26:52.693 - INFO: <epoch:  1, iter:   2,800> l_pix: 3.9372e-03 \n",
      "26-01-03 15:27:18.889 - INFO: <epoch:  1, iter:   2,900> l_pix: 7.0369e-03 \n",
      "26-01-03 15:27:41.626 - INFO: <epoch:  1, iter:   3,000> l_pix: 3.4641e-03 \n",
      "New beta scheduler set! rev_warmup70\n",
      "sampling loop time step: 100%|██████████████████| 34/34 [00:08<00:00,  4.06it/s]\n",
      "New beta scheduler set! rev_warmup70\n",
      "26-01-03 15:28:11.578 - INFO: <epoch:  1, iter:   3,100> l_pix: 4.6486e-03 \n",
      "26-01-03 15:28:33.099 - INFO: <epoch:  1, iter:   3,200> l_pix: 2.3508e-03 \n",
      "26-01-03 15:28:54.464 - INFO: <epoch:  1, iter:   3,300> l_pix: 6.6109e-03 \n",
      "26-01-03 15:29:14.976 - INFO: <epoch:  1, iter:   3,400> l_pix: 4.3569e-03 \n",
      "26-01-03 15:29:34.360 - INFO: <epoch:  2, iter:   3,500> l_pix: 4.4381e-03 \n",
      "26-01-03 15:29:56.648 - INFO: <epoch:  2, iter:   3,600> l_pix: 5.6063e-03 \n",
      "26-01-03 15:30:17.463 - INFO: <epoch:  2, iter:   3,700> l_pix: 1.2635e-02 \n",
      "26-01-03 15:30:37.590 - INFO: <epoch:  2, iter:   3,800> l_pix: 4.5926e-03 \n",
      "26-01-03 15:30:59.782 - INFO: <epoch:  2, iter:   3,900> l_pix: 4.0315e-03 \n",
      "26-01-03 15:31:19.604 - INFO: <epoch:  2, iter:   4,000> l_pix: 2.6499e-03 \n",
      "New beta scheduler set! rev_warmup70\n",
      "sampling loop time step: 100%|██████████████████| 34/34 [00:10<00:00,  3.35it/s]\n",
      "New beta scheduler set! rev_warmup70\n",
      "26-01-03 15:31:50.707 - INFO: <epoch:  2, iter:   4,100> l_pix: 7.2292e-03 \n",
      "26-01-03 15:32:11.058 - INFO: <epoch:  2, iter:   4,200> l_pix: 5.4865e-03 \n",
      "26-01-03 15:32:33.414 - INFO: <epoch:  2, iter:   4,300> l_pix: 4.6079e-03 \n",
      "26-01-03 15:32:55.601 - INFO: <epoch:  2, iter:   4,400> l_pix: 1.5427e-03 \n",
      "26-01-03 15:33:16.545 - INFO: <epoch:  2, iter:   4,500> l_pix: 2.8439e-03 \n",
      "26-01-03 15:33:38.621 - INFO: <epoch:  2, iter:   4,600> l_pix: 3.3849e-03 \n",
      "26-01-03 15:34:00.229 - INFO: <epoch:  2, iter:   4,700> l_pix: 3.0338e-03 \n",
      "26-01-03 15:34:21.894 - INFO: <epoch:  2, iter:   4,800> l_pix: 5.4039e-03 \n",
      "26-01-03 15:34:42.423 - INFO: <epoch:  2, iter:   4,900> l_pix: 7.5108e-03 \n",
      "26-01-03 15:35:03.683 - INFO: <epoch:  2, iter:   5,000> l_pix: 5.3388e-03 \n",
      "New beta scheduler set! rev_warmup70\n",
      "sampling loop time step: 100%|██████████████████| 34/34 [00:10<00:00,  3.26it/s]\n",
      "New beta scheduler set! rev_warmup70\n",
      "26-01-03 15:35:36.582 - INFO: <epoch:  2, iter:   5,100> l_pix: 3.4261e-03 \n",
      "26-01-03 15:35:58.542 - INFO: <epoch:  2, iter:   5,200> l_pix: 7.2317e-03 \n",
      "26-01-03 15:36:19.401 - INFO: <epoch:  2, iter:   5,300> l_pix: 3.5448e-03 \n",
      "26-01-03 15:36:41.481 - INFO: <epoch:  2, iter:   5,400> l_pix: 3.8203e-03 \n",
      "26-01-03 15:37:03.421 - INFO: <epoch:  2, iter:   5,500> l_pix: 8.0573e-03 \n",
      "26-01-03 15:37:24.002 - INFO: <epoch:  2, iter:   5,600> l_pix: 3.1210e-03 \n",
      "26-01-03 15:37:45.861 - INFO: <epoch:  2, iter:   5,700> l_pix: 4.8486e-03 \n",
      "26-01-03 15:38:06.901 - INFO: <epoch:  2, iter:   5,800> l_pix: 1.9418e-03 \n",
      "26-01-03 15:38:26.607 - INFO: <epoch:  2, iter:   5,900> l_pix: 5.8568e-03 \n",
      "26-01-03 15:38:48.043 - INFO: <epoch:  2, iter:   6,000> l_pix: 4.6468e-03 \n",
      "New beta scheduler set! rev_warmup70\n",
      "sampling loop time step: 100%|██████████████████| 34/34 [00:10<00:00,  3.13it/s]\n",
      "New beta scheduler set! rev_warmup70\n",
      "26-01-03 15:39:22.281 - INFO: <epoch:  2, iter:   6,100> l_pix: 3.2151e-03 \n",
      "26-01-03 15:39:43.425 - INFO: <epoch:  2, iter:   6,200> l_pix: 5.9410e-03 \n",
      "26-01-03 15:40:03.718 - INFO: <epoch:  2, iter:   6,300> l_pix: 6.5699e-03 \n",
      "26-01-03 15:40:26.710 - INFO: <epoch:  2, iter:   6,400> l_pix: 2.9111e-03 \n",
      "26-01-03 15:40:48.381 - INFO: <epoch:  2, iter:   6,500> l_pix: 4.6609e-03 \n",
      "26-01-03 15:41:09.016 - INFO: <epoch:  2, iter:   6,600> l_pix: 5.2366e-03 \n",
      "26-01-03 15:41:33.730 - INFO: <epoch:  2, iter:   6,700> l_pix: 4.3748e-03 \n",
      "26-01-03 15:41:54.532 - INFO: <epoch:  2, iter:   6,800> l_pix: 4.0270e-03 \n",
      "26-01-03 15:42:16.532 - INFO: <epoch:  2, iter:   6,900> l_pix: 3.2554e-03 \n",
      "Exception in thread Thread-4 (_pin_memory_loop):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/opt/conda/lib/python3.10/threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 51, in _pin_memory_loop\n",
      "    do_one_step()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 28, in do_one_step\n",
      "    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/queues.py\", line 122, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/reductions.py\", line 307, in rebuild_storage_fd\n",
      "    fd = df.detach()\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/resource_sharer.py\", line 57, in detach\n",
      "    with _resource_sharer.get_connection(self._id) as conn:\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/resource_sharer.py\", line 86, in get_connection\n",
      "    c = Client(address, authkey=process.current_process().authkey)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 502, in Client\n",
      "    c = SocketClient(address)\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/connection.py\", line 630, in SocketClient\n",
      "    s.connect(address)\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n",
      "Traceback (most recent call last):\n",
      "  File \"/host/c/Users/ROG/Documents/Github/DDM2_new/train_diff_model.py\", line 76, in <module>\n",
      "    diffusion.optimize_parameters()\n",
      "  File \"/host/c/Users/ROG/Documents/Github/DDM2_new/model/model.py\", line 95, in optimize_parameters\n",
      "    self.log_dict['l_pix'] = l_pix.item()\n",
      "KeyboardInterrupt\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# 训练扩散模型\n",
    "# 训练日志保存在 experiments/{name}/logs/\n",
    "# 验证结果保存在 experiments/{name}/results/\n",
    "# Checkpoint保存在 experiments/{name}/checkpoint/\n",
    "!CUDA_VISIBLE_DEVICES={GPU_ID} python3 train_diff_model.py -p train -c {CONFIG_FILE}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
